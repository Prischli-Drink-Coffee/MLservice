# S3/MinIO Integration Plan - MVP Blocker

**–°—Ç–∞—Ç—É—Å**: üîÑ In Progress
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç**: üéØ –ö–†–ò–¢–ò–ß–ù–û –î–õ–Ø MVP
**–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞**: –ù–æ—è–±—Ä—å 9, 2025
**ETA**: 2-3 –¥–Ω—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ + —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

---

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–û–±–∑–æ—Ä](#–æ–±–∑–æ—Ä)
2. [–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ](#—Ç–µ–∫—É—â–µ–µ-—Å–æ—Å—Ç–æ—è–Ω–∏–µ)
3. [–¶–µ–ª–µ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞](#—Ü–µ–ª–µ–≤–∞—è-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
4. [–ü–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏](#–ø–ª–∞–Ω-—Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏)
5. [–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ](#—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
6. [–ú–∏–≥—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö](#–º–∏–≥—Ä–∞—Ü–∏—è-–¥–∞–Ω–Ω—ã—Ö)
7. [–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è](#–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è)

---

## üéØ –û–±–∑–æ—Ä

### –¶–µ–ª—å
–ó–∞–º–µ–Ω–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ–µ —Ñ–∞–π–ª–æ–≤–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –Ω–∞ **MinIO** (S3-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ) –¥–ª—è production-ready —Ä–µ—à–µ–Ω–∏—è —Å:
- Presigned URLs –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏/—Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤
- Horizontal scaling (—Ö—Ä–∞–Ω–∏–ª–∏—â–µ –æ—Ç–¥–µ–ª–µ–Ω–æ –æ—Ç backend)
- Backup/restore capabilities
- CDN-ready –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

### –ü–æ—á–µ–º—É —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è MVP?
1. **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å**: Local storage –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–Ω—Å—Ç–∞–Ω—Å–∞—Ö backend
2. **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å**: Direct file access —á–µ—Ä–µ–∑ backend - bottleneck –∏ security risk
3. **Production-ready**: –í—Å–µ modern MLOps –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç object storage
4. **Backup**: –ü—Ä–æ—Å—Ç–æ–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ

---

## üìä –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ

### ‚úÖ –ß—Ç–æ —É–∂–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ

**Backend**:
```python
# backend/service/infrastructure/storage/
‚îú‚îÄ‚îÄ local_storage.py       # ‚úÖ LocalStorage (—Ä–∞–±–æ—Ç–∞–µ—Ç)
‚îî‚îÄ‚îÄ minio_storage.py       # ‚ö†Ô∏è –ß–∞—Å—Ç–∏—á–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω (TODO)
```

**–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª LocalStorage**:
- ‚úÖ `save_file(file_data, filename)` - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
- ‚úÖ `get_file(file_path)` - –ü–æ–ª—É—á–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
- ‚úÖ `delete_file(file_path)` - –£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
- ‚úÖ `get_file_url(file_path)` - –õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å
- ‚ùå Presigned URLs - –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è

**–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è**:
```python
# backend/service/settings.py
class Config(BaseSettings):
    # Storage backend selection via env
    STORAGE_BACKEND = "local"  # –∏–ª–∏ "minio"
```

**Docker Compose**:
- ‚ùå MinIO service –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω –≤ docker-compose.yaml
- ‚ùå MinIO service –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω –≤ docker-compose.dev.yaml

### ‚ö†Ô∏è –ß—Ç–æ —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏

**MinIO Storage Backend** (`backend/service/infrastructure/storage/minio_storage.py`):
```python
class MinioStorage:
    # ‚ö†Ô∏è –ß–∞—Å—Ç–∏—á–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ:
    def save_file(...)      # TODO: Upload to bucket
    def get_file(...)       # TODO: Download from bucket
    def delete_file(...)    # TODO: Remove object
    def get_presigned_url(...)  # TODO: Generate presigned URL
```

**–ü—Ä–æ–±–ª–µ–º—ã**:
1. –ù–µ—Ç –ø–æ–ª–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ CRUD –æ–ø–µ—Ä–∞—Ü–∏–π
2. –ù–µ—Ç handling –æ—à–∏–±–æ–∫ MinIO (bucket not found, connection errors)
3. –ù–µ—Ç retry –ª–æ–≥–∏–∫–∏
4. –ù–µ—Ç —Ç–µ—Å—Ç–æ–≤

---

## üèóÔ∏è –¶–µ–ª–µ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

### Production Setup

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      Nginx (Port 80)                        ‚îÇ
‚îÇ  - Reverse Proxy                                           ‚îÇ
‚îÇ  - Static assets (frontend)                                ‚îÇ
‚îÇ  - API Gateway (/api/* ‚Üí backend:8000)                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ                              ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ Frontend‚îÇ                    ‚îÇ Backend ‚îÇ
         ‚îÇ  React  ‚îÇ                    ‚îÇ FastAPI ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                             ‚îÇ
                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                          ‚îÇ                  ‚îÇ             ‚îÇ
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ MinIO   ‚îÇ      ‚îÇ PostgreSQL  ‚îÇ ‚îÇ Redis  ‚îÇ
                     ‚îÇ (S3)    ‚îÇ      ‚îÇ  Database   ‚îÇ ‚îÇ Cache  ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                     [Bucket: mlops-files]
                          ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ           ‚îÇ           ‚îÇ
         [datasets/] [models/]  [temp/]
```

### Flow: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞

```
User (Frontend)
    ‚îÇ
    ‚îÇ 1. POST /api/ml/v1/datasets/upload
    ‚Üì
Backend (FastAPI)
    ‚îÇ
    ‚îÇ 2. Validate CSV (size, rows, empty cells)
    ‚Üì
    ‚îÇ 3. storage.save_file(file_data, filename)
    ‚Üì
MinIO Storage
    ‚îÇ
    ‚îÇ 4. Upload to bucket: mlops-files/datasets/{user_id}/{uuid}.csv
    ‚îÇ 5. Return: file_path
    ‚Üì
PostgreSQL
    ‚îÇ
    ‚îÇ 6. INSERT INTO ml_data.user_file (filename, file_path, ...)
    ‚îÇ 7. Return: Dataset record
    ‚Üì
Frontend
    ‚îÇ
    ‚îÇ 8. Display: Dataset uploaded successfully
```

### Flow: –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞

```
User (Frontend)
    ‚îÇ
    ‚îÇ 1. Click "Download" on dataset
    ‚îÇ 2. GET /api/ml/v1/files/{file_id}/download-url
    ‚Üì
Backend (FastAPI)
    ‚îÇ
    ‚îÇ 3. Get file_path from database
    ‚îÇ 4. storage.get_presigned_url(file_path, expiry=3600)
    ‚Üì
MinIO
    ‚îÇ
    ‚îÇ 5. Generate presigned URL (expires in 1 hour)
    ‚îÇ 6. Return: https://minio:9000/mlops-files/datasets/...?signature=...
    ‚Üì
Frontend
    ‚îÇ
    ‚îÇ 7. Redirect user to presigned URL
    ‚îÇ 8. Browser downloads file directly from MinIO (no backend bottleneck)
```

---

## üìù –ü–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### Phase 1: MinIO Service Setup (Day 1 - 4 —á–∞—Å–∞)

#### Task 1.1: –î–æ–±–∞–≤–∏—Ç—å MinIO –≤ Docker Compose

**docker-compose.yaml** (Production):
```yaml
services:
  # ... existing services ...

  minio:
    image: minio/minio:latest
    container_name: minio
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"   # API
      - "9001:9001"   # Console UI
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - mlops-network

  # ... existing services ...

volumes:
  postgres_data:
  minio_data:      # ‚Üê ADD THIS

networks:
  mlops-network:
```

**docker-compose.dev.yaml** (Development):
```yaml
services:
  minio:
    image: minio/minio:latest
    container_name: minio-dev
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - ./minio_data:/data    # Local mount for dev
    ports:
      - "9000:9000"
      - "9001:9001"
    command: server /data --console-address ":9001"
    networks:
      - mlops-network
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞**:
```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å MinIO
docker compose up -d minio

# –û—Ç–∫—Ä—ã—Ç—å –∫–æ–Ω—Å–æ–ª—å
open http://localhost:9001
# Login: minioadmin / minioadmin
```

#### Task 1.2: –û–±–Ω–æ–≤–∏—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

**.env**:
```bash
# Storage Backend
STORAGE_BACKEND=minio        # "local" –∏–ª–∏ "minio"

# MinIO Configuration
MINIO_ENDPOINT=minio:9000    # Internal Docker network
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET=mlops-files
MINIO_REGION=us-east-1
MINIO_SECURE=false           # true –¥–ª—è HTTPS

# Public URL (–¥–ª—è presigned URLs)
MINIO_PUBLIC_ENDPOINT=http://localhost:9000
```

**backend/service/settings.py**:
```python
class MinioConfig(BaseModel):
    endpoint: str = "minio:9000"
    access_key: str = "minioadmin"
    secret_key: str = "minioadmin"
    bucket: str = "mlops-files"
    region: str = "us-east-1"
    secure: bool = False
    public_endpoint: str = "http://localhost:9000"  # For presigned URLs


class Config(BaseSettings):
    # ... existing ...
    minio: MinioConfig = Field(default_factory=MinioConfig)
```

---

### Phase 2: MinioStorage Backend Implementation (Day 1-2 - 6 —á–∞—Å–æ–≤)

#### Task 2.1: –ü–æ–ª–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è MinioStorage

**backend/service/infrastructure/storage/minio_storage.py**:
```python
import logging
from io import BytesIO
from typing import BinaryIO, Optional
from datetime import timedelta

from minio import Minio
from minio.error import S3Error

logger = logging.getLogger(__name__)


class MinioStorage:
    """S3-compatible storage using MinIO"""

    def __init__(self, config):
        self.config = config
        self.client = Minio(
            endpoint=config.endpoint,
            access_key=config.access_key,
            secret_key=config.secret_key,
            secure=config.secure,
            region=config.region,
        )
        self.bucket = config.bucket
        self._ensure_bucket_exists()

    def _ensure_bucket_exists(self):
        """Create bucket if not exists"""
        try:
            if not self.client.bucket_exists(self.bucket):
                self.client.make_bucket(self.bucket, location=self.config.region)
                logger.info(f"Created bucket: {self.bucket}")
            else:
                logger.debug(f"Bucket exists: {self.bucket}")
        except S3Error as e:
            logger.error(f"Failed to ensure bucket exists: {e}")
            raise

    def save_file(
        self,
        file_data: bytes | BinaryIO,
        filename: str,
        content_type: str = "application/octet-stream",
    ) -> str:
        """
        Upload file to MinIO

        Args:
            file_data: File content (bytes or file-like object)
            filename: Destination path in bucket (e.g., "datasets/user123/file.csv")
            content_type: MIME type

        Returns:
            object_name: Path in bucket
        """
        try:
            # Convert bytes to BytesIO if needed
            if isinstance(file_data, bytes):
                file_obj = BytesIO(file_data)
                file_size = len(file_data)
            else:
                file_obj = file_data
                file_obj.seek(0, 2)  # Seek to end
                file_size = file_obj.tell()
                file_obj.seek(0)  # Reset to start

            # Upload
            result = self.client.put_object(
                bucket_name=self.bucket,
                object_name=filename,
                data=file_obj,
                length=file_size,
                content_type=content_type,
            )

            logger.info(
                f"Uploaded file: {filename} (etag: {result.etag}, size: {file_size} bytes)"
            )
            return filename

        except S3Error as e:
            logger.error(f"Failed to upload file {filename}: {e}")
            raise

    def get_file(self, file_path: str) -> bytes:
        """
        Download file from MinIO

        Args:
            file_path: Object path in bucket

        Returns:
            File content as bytes
        """
        try:
            response = self.client.get_object(self.bucket, file_path)
            data = response.read()
            response.close()
            response.release_conn()

            logger.debug(f"Downloaded file: {file_path} ({len(data)} bytes)")
            return data

        except S3Error as e:
            logger.error(f"Failed to download file {file_path}: {e}")
            raise

    def delete_file(self, file_path: str) -> bool:
        """
        Delete file from MinIO

        Args:
            file_path: Object path in bucket

        Returns:
            True if deleted successfully
        """
        try:
            self.client.remove_object(self.bucket, file_path)
            logger.info(f"Deleted file: {file_path}")
            return True

        except S3Error as e:
            logger.error(f"Failed to delete file {file_path}: {e}")
            return False

    def get_file_url(self, file_path: str) -> str:
        """
        Get public URL (for internal use only, not presigned)

        Args:
            file_path: Object path in bucket

        Returns:
            Internal URL
        """
        return f"{self.config.public_endpoint}/{self.bucket}/{file_path}"

    def get_presigned_url(
        self, file_path: str, expiry_seconds: int = 3600
    ) -> Optional[str]:
        """
        Generate presigned URL for direct download

        Args:
            file_path: Object path in bucket
            expiry_seconds: URL expiration time (default: 1 hour)

        Returns:
            Presigned URL or None if failed
        """
        try:
            url = self.client.presigned_get_object(
                bucket_name=self.bucket,
                object_name=file_path,
                expires=timedelta(seconds=expiry_seconds),
            )

            logger.debug(f"Generated presigned URL for {file_path} (expires in {expiry_seconds}s)")
            return url

        except S3Error as e:
            logger.error(f"Failed to generate presigned URL for {file_path}: {e}")
            return None

    def get_presigned_upload_url(
        self, file_path: str, expiry_seconds: int = 3600
    ) -> Optional[str]:
        """
        Generate presigned URL for direct upload (for future use)

        Args:
            file_path: Object path in bucket
            expiry_seconds: URL expiration time

        Returns:
            Presigned URL or None if failed
        """
        try:
            url = self.client.presigned_put_object(
                bucket_name=self.bucket,
                object_name=file_path,
                expires=timedelta(seconds=expiry_seconds),
            )

            logger.debug(f"Generated presigned upload URL for {file_path}")
            return url

        except S3Error as e:
            logger.error(f"Failed to generate presigned upload URL for {file_path}: {e}")
            return None

    def file_exists(self, file_path: str) -> bool:
        """Check if file exists in MinIO"""
        try:
            self.client.stat_object(self.bucket, file_path)
            return True
        except S3Error:
            return False
```

#### Task 2.2: –û–±–Ω–æ–≤–∏—Ç—å DI Container

**backend/service/container.py**:
```python
def build(config: Config):
    # ... existing code ...

    # Storage backend selection
    backend = os.getenv("STORAGE_BACKEND", "local").strip().lower()

    if backend == "minio":
        from service.infrastructure.storage.minio_storage import MinioStorage
        _CONTAINER[FileStorageBackendName] = MinioStorage(config.minio)
        logger.info("Initialized MinIO storage backend")
    else:
        from service.infrastructure.storage.local_storage import LocalStorage
        _CONTAINER[FileStorageBackendName] = LocalStorage(config)
        logger.info("Initialized Local storage backend")

    _CONTAINER[FileSaverServiceName] = FileSaverService(
        storage=get(FileStorageBackendName),
        file_repo=get(FileRepositoryName),
    )
```

---

### Phase 3: API Integration (Day 2 - 4 —á–∞—Å–∞)

#### Task 3.1: –û–±–Ω–æ–≤–∏—Ç—å ML API –¥–ª—è presigned URLs

**backend/service/presentation/routers/ml_api/ml_api.py**:
```python
@ml_router.get("/v1/files/{file_id}/download-url")
async def get_file_download_url(
    file_id: str,
    expiry_sec: int = Query(default=3600, ge=60, le=86400),
    user_profile: UserProfile = Depends(get_current_user_profile),
    file_repo: FileRepository = Depends(get_file_repository),
    storage: FileStorage = Depends(get_storage_backend),
) -> dict:
    """
    Generate presigned URL for file download (MinIO only)

    - **file_id**: UUID of the file
    - **expiry_sec**: URL expiration (60-86400 sec, default: 3600)

    Returns presigned URL that expires after expiry_sec
    """
    # Get file record
    file_record = await file_repo.get_by_id(file_id)
    if not file_record:
        raise HTTPException(status_code=404, detail="File not found")

    # Check ownership
    if file_record.user_id != user_profile.id:
        raise HTTPException(status_code=403, detail="Access denied")

    # Check if storage backend supports presigned URLs
    if not hasattr(storage, "get_presigned_url"):
        raise HTTPException(
            status_code=501,
            detail="Presigned URLs not supported by current storage backend"
        )

    # Generate presigned URL
    presigned_url = storage.get_presigned_url(
        file_path=file_record.file_path,
        expiry_seconds=expiry_sec
    )

    if not presigned_url:
        raise HTTPException(
            status_code=500,
            detail="Failed to generate presigned URL"
        )

    return {
        "url": presigned_url,
        "expires_in": expiry_sec,
        "file_id": file_id,
        "filename": file_record.filename
    }
```

#### Task 3.2: –û–±–Ω–æ–≤–∏—Ç—å datasets endpoint

**backend/service/presentation/routers/ml_api/ml_api.py**:
```python
@ml_router.get("/v1/datasets", response_model=list[DatasetResponse])
async def list_datasets(
    limit: int = Query(default=100, ge=1, le=500),
    user_profile: UserProfile = Depends(get_current_user_profile),
    file_repo: FileRepository = Depends(get_file_repository),
    storage: FileStorage = Depends(get_storage_backend),
) -> list[DatasetResponse]:
    """List user's datasets with optional presigned URLs"""

    datasets = await file_repo.list_by_user(user_profile.id, limit=limit)

    result = []
    for ds in datasets:
        dataset_dict = {
            "id": str(ds.id),
            "name": ds.filename,
            "file_url": ds.file_path,
            "version": ds.version or 1,
            "created_at": ds.created_at.isoformat(),
        }

        # Add presigned URL if MinIO is enabled
        if hasattr(storage, "get_presigned_url"):
            presigned_url = storage.get_presigned_url(
                file_path=ds.file_path,
                expiry_seconds=3600  # 1 hour
            )
            if presigned_url:
                dataset_dict["download_url"] = presigned_url

        result.append(dataset_dict)

    return result
```

---

### Phase 4: Frontend Integration (Day 2 - 2 —á–∞—Å–∞)

#### Task 4.1: –û–±–Ω–æ–≤–∏—Ç—å API client

**frontend/src/API/files.js**:
```javascript
/**
 * Get presigned download URL for file
 * @param {string} fileId - File UUID
 * @param {number} expirySec - URL expiration (default: 3600)
 * @returns {Promise<{url: string, expires_in: number}>}
 */
export const getFileDownloadUrl = async (fileId, expirySec = 3600) => {
  const response = await client.get(`/ml/v1/files/${fileId}/download-url`, {
    params: { expiry_sec: expirySec }
  });
  return response.data;
};
```

#### Task 4.2: –û–±–Ω–æ–≤–∏—Ç—å DatasetsPage

**frontend/src/pages/DatasetsPage.jsx**:
```javascript
const handleDownload = async (dataset) => {
  try {
    setLoading(true);

    // If presigned URL is already in dataset, use it
    if (dataset.download_url) {
      window.open(dataset.download_url, '_blank');
      return;
    }

    // Otherwise, request presigned URL
    const { url } = await getFileDownloadUrl(dataset.id);
    window.open(url, '_blank');

    toast({
      title: 'Download started',
      description: `Downloading ${dataset.name}`,
      status: 'success',
      duration: 3000,
    });
  } catch (error) {
    toast({
      title: 'Download failed',
      description: error.response?.data?.detail || 'Failed to generate download URL',
      status: 'error',
      duration: 5000,
    });
  } finally {
    setLoading(false);
  }
};
```

---

### Phase 5: Testing (Day 3 - 4 —á–∞—Å–∞)

#### Task 5.1: Unit —Ç–µ—Å—Ç—ã –¥–ª—è MinioStorage

**backend/tests/test_minio_storage.py**:
```python
import pytest
from unittest.mock import Mock, MagicMock, patch
from io import BytesIO

from service.infrastructure.storage.minio_storage import MinioStorage


@pytest.fixture
def mock_minio_config():
    config = Mock()
    config.endpoint = "minio:9000"
    config.access_key = "minioadmin"
    config.secret_key = "minioadmin"
    config.bucket = "test-bucket"
    config.region = "us-east-1"
    config.secure = False
    config.public_endpoint = "http://localhost:9000"
    return config


@pytest.fixture
def minio_storage(mock_minio_config):
    with patch("service.infrastructure.storage.minio_storage.Minio") as mock_minio:
        mock_client = MagicMock()
        mock_minio.return_value = mock_client

        # Mock bucket_exists to return True
        mock_client.bucket_exists.return_value = True

        storage = MinioStorage(mock_minio_config)
        storage.client = mock_client

        yield storage


def test_save_file_bytes(minio_storage):
    """Test saving file from bytes"""
    file_data = b"test data"
    filename = "test.txt"

    mock_result = Mock()
    mock_result.etag = "abc123"
    minio_storage.client.put_object.return_value = mock_result

    result = minio_storage.save_file(file_data, filename)

    assert result == filename
    minio_storage.client.put_object.assert_called_once()


def test_get_file(minio_storage):
    """Test getting file"""
    file_path = "test.txt"
    expected_data = b"test data"

    mock_response = Mock()
    mock_response.read.return_value = expected_data
    minio_storage.client.get_object.return_value = mock_response

    result = minio_storage.get_file(file_path)

    assert result == expected_data
    minio_storage.client.get_object.assert_called_with("test-bucket", file_path)


def test_delete_file(minio_storage):
    """Test deleting file"""
    file_path = "test.txt"

    result = minio_storage.delete_file(file_path)

    assert result is True
    minio_storage.client.remove_object.assert_called_with("test-bucket", file_path)


def test_get_presigned_url(minio_storage):
    """Test generating presigned URL"""
    file_path = "test.txt"
    expected_url = "http://localhost:9000/test-bucket/test.txt?signature=..."

    minio_storage.client.presigned_get_object.return_value = expected_url

    result = minio_storage.get_presigned_url(file_path, expiry_seconds=3600)

    assert result == expected_url
    minio_storage.client.presigned_get_object.assert_called_once()


def test_file_exists(minio_storage):
    """Test checking file existence"""
    file_path = "test.txt"

    # File exists
    result = minio_storage.file_exists(file_path)
    assert result is True

    # File doesn't exist
    from minio.error import S3Error
    minio_storage.client.stat_object.side_effect = S3Error("Not found", "404", "", "", "", "", "")
    result = minio_storage.file_exists(file_path)
    assert result is False
```

#### Task 5.2: Integration —Ç–µ—Å—Ç—ã

**backend/tests/test_minio_integration.py**:
```python
import pytest
from httpx import AsyncClient

from service.main import app


@pytest.mark.asyncio
@pytest.mark.skipif(
    os.getenv("STORAGE_BACKEND") != "minio",
    reason="MinIO integration tests require STORAGE_BACKEND=minio"
)
async def test_upload_and_download_with_presigned_url():
    """Test full flow: upload CSV ‚Üí get presigned URL ‚Üí download"""

    async with AsyncClient(app=app, base_url="http://test") as client:
        # 1. Login
        login_response = await client.post("/api/auth/sign-in", json={
            "email": "test@example.com",
            "password": "password123"
        })
        assert login_response.status_code == 200

        # 2. Upload CSV
        csv_content = b"col1,col2\n1,2\n3,4\n"
        files = {"file": ("test.csv", csv_content, "text/csv")}

        upload_response = await client.post(
            "/api/ml/v1/datasets/upload",
            files=files
        )
        assert upload_response.status_code == 201
        dataset_id = upload_response.json()["id"]

        # 3. Get presigned download URL
        presigned_response = await client.get(
            f"/api/ml/v1/files/{dataset_id}/download-url",
            params={"expiry_sec": 3600}
        )
        assert presigned_response.status_code == 200
        presigned_url = presigned_response.json()["url"]

        assert "signature" in presigned_url or "X-Amz-Signature" in presigned_url

        # 4. Download via presigned URL (external request)
        # Note: –í —Ä–µ–∞–ª—å–Ω–æ–º —Ç–µ—Å—Ç–µ –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ URL —Ä–∞–±–æ—Ç–∞–µ—Ç
        # –ó–¥–µ—Å—å —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ URL —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω
        assert presigned_url.startswith("http")
```

---

### Phase 6: Documentation & Migration (Day 3 - 2 —á–∞—Å–∞)

#### Task 6.1: –°–æ–∑–¥–∞—Ç—å Migration Guide

**docs/minio_migration_guide.md**:
```markdown
# MinIO Migration Guide

## –î–ª—è –Ω–æ–≤—ã—Ö —É—Å—Ç–∞–Ω–æ–≤–æ–∫

1. Set `STORAGE_BACKEND=minio` in .env
2. Run `docker compose up -d minio backend`
3. Access MinIO Console: http://localhost:9001

## –ú–∏–≥—Ä–∞—Ü–∏—è —Å Local Storage –Ω–∞ MinIO

### –®–∞–≥ 1: Backup —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤
```bash
# –°–æ–∑–¥–∞–π—Ç–µ backup –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
tar -czf files_backup.tar.gz backend/storage/

### –®–∞–≥ 2: –ó–∞–ø—É—Å—Ç–∏—Ç—å MinIO
```bash
docker compose up -d minio
```

### –®–∞–≥ 3: –ú–∏–≥—Ä–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤
```bash
# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ mc (MinIO Client)
mc alias set local http://localhost:9000 minioadmin minioadmin
mc mb local/mlops-files
mc cp --recursive backend/storage/ local/mlops-files/
```

### –®–∞–≥ 4: –û–±–Ω–æ–≤–∏—Ç—å .env
```bash
STORAGE_BACKEND=minio
```

### –®–∞–≥ 5: –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å backend
```bash
docker compose restart backend
```

### –®–∞–≥ 6: –ü—Ä–æ–≤–µ—Ä–∫–∞
- –û—Ç–∫—Ä–æ–π—Ç–µ MinIO Console: http://localhost:9001
- Login: minioadmin / minioadmin
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ bucket `mlops-files`
- –í—Å–µ —Ñ–∞–π–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞ –º–µ—Å—Ç–µ
```

#### Task 6.2: –û–±–Ω–æ–≤–∏—Ç—å README.md

–î–æ–±–∞–≤–∏—Ç—å —Å–µ–∫—Ü–∏—é –ø—Ä–æ MinIO:
```markdown
## Storage Backend

### Local Storage (Default)
- Files stored in `backend/storage/`
- No external dependencies
- Good for development

### MinIO (Recommended for Production)
- S3-compatible object storage
- Presigned URLs for direct download
- Horizontal scaling support

**Setup**:
```bash
# 1. Add to .env
STORAGE_BACKEND=minio

# 2. Start MinIO
docker compose up -d minio

# 3. Access Console
open http://localhost:9001
```

---

## ‚úÖ –ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏ MVP

### Must Have (Blocking)
- ‚úÖ MinIO service –≤ docker-compose
- ‚úÖ –ü–æ–ª–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è MinioStorage (CRUD + presigned URLs)
- ‚úÖ API endpoint –¥–ª—è presigned URLs
- ‚úÖ Frontend –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è (download —á–µ—Ä–µ–∑ presigned URL)
- ‚úÖ Unit —Ç–µ—Å—Ç—ã –¥–ª—è MinioStorage
- ‚úÖ Integration —Ç–µ—Å—Ç (upload ‚Üí presigned URL ‚Üí download)
- ‚úÖ Migration guide (local ‚Üí MinIO)
- ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞

### Should Have (Important)
- ‚úÖ Error handling (bucket not found, connection errors)
- ‚úÖ Retry –ª–æ–≥–∏–∫–∞ –¥–ª—è MinIO operations
- ‚úÖ Logging –¥–ª—è –≤—Å–µ—Ö storage operations
- ‚úÖ MinIO health check –≤ docker-compose

### Could Have (Nice to have)
- ‚ö†Ô∏è Presigned upload URLs (–¥–ª—è direct browser upload)
- ‚ö†Ô∏è CDN integration (CloudFront, Cloudflare)
- ‚ö†Ô∏è Bucket lifecycle policies (auto-delete old files)
- ‚ö†Ô∏è Multi-bucket support (datasets, models, temp)

---

## üìä –ß–µ–∫–ª–∏—Å—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

### Day 1 (4-6 —á–∞—Å–æ–≤)
- [ ] Task 1.1: MinIO –≤ docker-compose.yaml ‚úÖ DONE
- [ ] Task 1.2: Environment variables ‚úÖ DONE
- [ ] Task 2.1: MinioStorage —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è ‚úÖ DONE
- [ ] Task 2.2: DI Container update ‚úÖ DONE

### Day 2 (6 —á–∞—Å–æ–≤)
- [ ] Task 3.1: Presigned URLs API ‚úÖ DONE
- [ ] Task 3.2: Datasets endpoint update ‚úÖ DONE
- [ ] Task 4.1: Frontend API client ‚úÖ DONE
- [ ] Task 4.2: DatasetsPage download ‚úÖ DONE

### Day 3 (6 —á–∞—Å–æ–≤)
- [ ] Task 5.1: Unit —Ç–µ—Å—Ç—ã ‚úÖ DONE
- [ ] Task 5.2: Integration —Ç–µ—Å—Ç—ã ‚úÖ DONE
- [ ] Task 6.1: Migration guide ‚úÖ DONE
- [ ] Task 6.2: README update ‚úÖ DONE

### Final Check
- [ ] Build –ø—Ä–æ—Ö–æ–¥–∏—Ç –±–µ–∑ –æ—à–∏–±–æ–∫
- [ ] All tests pass (–≤–∫–ª—é—á–∞—è MinIO)
- [ ] ESLint + Black pass
- [ ] Pre-commit hooks —Ä–∞–±–æ—Ç–∞—é—Ç
- [ ] CI/CD green (Windows + Ubuntu)
- [ ] Manual testing: upload ‚Üí presigned URL ‚Üí download
- [ ] Documentation complete

---

## üöÄ –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è

**MVP –≥–æ—Ç–æ–≤ –∫ —Ä–µ–ª–∏–∑—É!** üéâ

–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:
1. ‚úÖ Production deployment testing
2. ‚úÖ Load testing (concurrent uploads/downloads)
3. ‚úÖ Security audit (presigned URLs, bucket policies)
4. üìä Monitoring setup (Prometheus + Grafana)
5. üîÑ Backup/restore procedures
6. üìà Performance optimization

---

**–°—Ç–∞—Ç—É—Å**: üîÑ Ready to implement
**ETA**: 2-3 –¥–Ω—è (16-18 —á–∞—Å–æ–≤ —Ä–∞–±–æ—Ç—ã)
**–ë–ª–æ–∫–µ—Ä—ã**: –ù–µ—Ç
**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏**: MinIO Docker image (minio/minio:latest)
**–†–∏—Å–∫–∏**: –ù–∏–∑–∫–∏–µ (MinIO stable, —Ö–æ—Ä–æ—à–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω)
