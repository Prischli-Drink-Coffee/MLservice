```markdown
# TPOT Integration Plan ‚Äî Training Jobs Upgrade

**–°—Ç–∞—Ç—É—Å**: üü° –ü–ª–∞–Ω —É—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç—Å—è
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç**: üéØ –ö–†–ò–¢–ò–ß–ù–û –î–õ–Ø Q1 2026
**–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞**: –ù–æ—è–±—Ä—å 27, 2025
**ETA**: 2 —Å–ø—Ä–∏–Ω—Ç–∞ —Å –±—É—Ñ–µ—Ä–∞–º–∏

---

## üìö –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–û–±–∑–æ—Ä –∏ —Ü–µ–ª–∏](#–æ–±–∑–æ—Ä-–∏-—Ü–µ–ª–∏)
2. [–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ](#—Ç–µ–∫—É—â–µ–µ-—Å–æ—Å—Ç–æ—è–Ω–∏–µ)
3. [–¶–µ–ª–µ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞](#—Ü–µ–ª–µ–≤–∞—è-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
4. [–î–æ—Ä–æ–∂–Ω–∞—è –∫–∞—Ä—Ç–∞ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è](#–¥–æ—Ä–æ–∂–Ω–∞—è-–∫–∞—Ä—Ç–∞-–≤–Ω–µ–¥—Ä–µ–Ω–∏—è)
5. [–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ —Ä–µ–∂–∏–º—ã](#–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ-—Ä–µ–∂–∏–º—ã)
6. [–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã](#–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è-–∏-–ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
7. [–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ QA](#—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ-–∏-qa)
8. [–ù–∞–±–ª—é–¥–∞–µ–º–æ—Å—Ç—å –∏ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è](#–Ω–∞–±–ª—é–¥–∞–µ–º–æ—Å—Ç—å-–∏-—ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è)
9. [–†–∏—Å–∫–∏ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏](#—Ä–∏—Å–∫–∏-–∏-–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏)
10. [–ü–ª–∞–Ω —Ä–∞—Å–∫–∞—Ç–∫–∏](#–ø–ª–∞–Ω-—Ä–∞—Å–∫–∞—Ç–∫–∏)
11. [–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –æ–±—É—á–µ–Ω–∏–µ](#–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è-–∏-–æ–±—É—á–µ–Ω–∏–µ)

---

## üéØ –û–±–∑–æ—Ä –∏ —Ü–µ–ª–∏

### –ß—Ç–æ –º–µ–Ω—è–µ–º
- –ü–µ—Ä–µ–≤–æ–¥–∏–º TrainingService —Å —Ä—É—á–Ω—ã—Ö `LinearRegression`/`LogisticRegression` –Ω–∞ TPOT, –∏—Å–ø–æ–ª—å–∑—É—è —ç–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ pipeline-—Å—Ç—Ä—É–∫—Ç—É—Ä –∏ –∫–∞—Å—Ç–æ–º–Ω—ã–µ `ConfigSpace`/`dict` (GraphSearchPipeline, ChoicePipeline, FSSNode, EstimatorNode).
- –î–æ–±–∞–≤–ª—è–µ–º –±–æ–≥–∞—Ç—ã–π leaderboard, Pareto front –∏ KPI (`best_pipeline`, `tp_generations`, `tp_population_size`).
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ñ–ª–∞–≥–∏ `ENABLE_AUTOML`, `TPOT_PARALLEL_MODE` —Å `local`/`distributed` —Ä–µ–∂–∏–º–∞–º–∏, —Å–æ—Ö—Ä–∞–Ω—è—è fallback –Ω–∞ –ª–µ–≥–∫–æ–≤–µ—Å–Ω—É—é –ª–æ–≥–∏–∫—É –æ–±—É—á–µ–Ω–∏—è.

### –ö–ª—é—á–µ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –º–æ–¥–µ–ª–µ–π –∑–∞–º–µ–Ω—è–µ—Ç —Ä—É—á–Ω—ã–µ –ø–æ–¥–±–æ—Ä—ã –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
- –°—Ç–∞–±–∏–ª—å–Ω—ã–π rollout —Å –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º—ã–º —Ä–µ—Å—É—Ä—Å–Ω—ã–º –±—é–¥–∂–µ—Ç–æ–º.
- –ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ TPOT (Pareto front, leaderboard) –¥–æ—Å—Ç—É–ø–Ω—ã –≤ UI/Swagger.

### –ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏
- TPOT –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, fallback –æ—Å—Ç–∞—ë—Ç—Å—è –¥–æ—Å—Ç—É–ø–Ω—ã–º.
- Payload —Å–æ–¥–µ—Ä–∂–∏—Ç `metric`, `target_column`, `generations`, `parallel_mode`.
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã (–≤–∫–ª—é—á–∞—è `docs/tpot.md`).

---

## üîç –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ

| –û–±–ª–∞—Å—Ç—å | –°–æ—Å—Ç–æ—è–Ω–∏–µ | –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è |
|--------|-----------|-------------|
|TrainingService|–†—É—á–Ω—ã–µ baseline-–º–æ–¥–µ–ª–∏|–ù–µ—Ç –∞–≤—Ç–æML, –Ω–µ—Ç leaderboard|
|Payload|–í–µ—Ä—Å–∏—è —Ç–æ–ª—å–∫–æ `target_column`, `task`|–ù–µ–ª—å–∑—è –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å –±—é–¥–∂–µ—Ç—ã/–º–µ—Ç—Ä–∏–∫–∏|
|–ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞|Backend —Ä–∞–±–æ—Ç–∞–µ—Ç –æ–¥–Ω–æ–ø—Ä–æ—Ü–µ—Å—Å–Ω–æ|–ù–µ—Ç Dask scheduler/workers –ø—Ä–æ—Ü–µ—Å—Å–æ–≤|
|–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è|–ï—Å—Ç—å auto-sklearn guide|–ù—É–∂–Ω–æ –ø–µ—Ä–µ–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ TPOT|

---

## üèóÔ∏è –¶–µ–ª–µ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FastAPI Backend                                            ‚îÇ
‚îÇ  ‚îú‚îÄ TrainingService                                        ‚îÇ
‚îÇ  ‚îÇ   ‚îú‚îÄ TPOTTrainer (TPOTClassifier/TPOTRegressor)          ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ     ‚îú‚îÄ SearchSpace (ConfigSpace/GraphSearchPipeline)‚îÇ
‚îÇ  ‚îÇ   ‚îÇ     ‚îú‚îÄ Dask Client -> TPOTEstimator                 ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ     ‚îú‚îÄ Serialization (leaderboard, pipeline, metrics)‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ Fallback Trainer (legacy pipeline)                 ‚îÇ
‚îÇ  ‚îî‚îÄ Monitoring & Logging                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ                    ‚îÇ              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇLocal n_jobs         ‚îÇ ‚îÇDask Scheduler/     ‚îÇ ‚îÇMinIO / FS Storage‚îÇ
‚îÇ(TPOT_PARALLEL_MODE=local)‚îÇ‚îÇWorkers (--scheduler-file)‚îÇ‚îÇmodel.joblib + leaderboard‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

- `TPOTTrainer` —Å—Ç—Ä–æ–∏—Ç `ConfigSpace`-–±–∞–∑–æ–≤—ã–µ search spaces, –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å `TPOT__CONFIG_DICT` –∏–ª–∏ –ø–µ—Ä–µ–¥–∞—Ç—å —É–∑–ª—ã (EstimatorNode, ChoicePipeline, GraphSearchPipeline).
- –°–æ—Ö—Ä–∞–Ω—è–µ–º `model.joblib`, `leaderboard.json`, `tp_pareto_front.json`, `evaluation_summary`.
- Backend –ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ Dask client –∏ –ø–µ—Ä–µ–¥–∞—ë—Ç –µ–≥–æ –≤ `TPOTEstimator`, –ª–∏–±–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `n_jobs` –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞.

---

## üõ£Ô∏è –î–æ—Ä–æ–∂–Ω–∞—è –∫–∞—Ä—Ç–∞ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è

### Phase 0 ‚Äî –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è (3-4 –¥–Ω—è)
1. Dockerfile: `build-essential`, `graphviz`, `swig`, `cmake`, `libopenblas-dev`, `libomp-dev`.
2. Python deps:
   - `tpot>=0.12`, `ConfigSpace>=0.6`, `dask[distributed]`, `joblib>=1.3`, `scikit-learn>=1.5`, `numpy`, `pandas`.
   - `uv pip compile`, –æ–±–Ω–æ–≤–∏—Ç—å `requirements.txt`, `uv.lock`.
3. CI: –∫–µ—à –∫–æ–ª–µ—Å, —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–µ —Ç–∞–π–º–∞—É—Ç—ã.
4. Feature flags: `ENABLE_AUTOML`, `ENABLE_AUTOML_FALLBACK`, `TPOT_PARALLEL_MODE`, `TPOT__CONFIG_DICT`.

### Phase 1 ‚Äî –ë–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞ (1 –Ω–µ–¥–µ–ª—è)
1. –°–æ–∑–¥–∞—Ç—å `service/services/automl/` —Å `search_space`, `tpot_trainer`, `serialization`.
2. `TPOTTrainer.train()`:
   - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ `target_column`, `feat_type`, `CustomConfigSpace`.
   - `generations`, `population_size`, `time_left`, `per_run_limit`, `dask_client`.
   - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ `leaderboard_topk`, `evaluated_individuals`, `Pareto_Front`.
3. `TrainingService`: –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è `TPOTTrainer`, fallback, –º–µ—Ç—Ä–∏–∫–∏ `tp_generations`, `leaderboard_topk`, `parallel_mode`.
4. `settings.py`, `container.py`: –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ env vars, `TPOT__CONFIG_DICT` (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é `"linear"` –∏–ª–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ TPOT API ‚Äî `tpot.config.get_search_space('regressors')`).

### Phase 2 ‚Äî –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç—å –∏ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (4-5 –¥–Ω–µ–π)
1. `docker-compose`: `tpot-scheduler`, `tpot-worker` (volume —Å `/var/run/tpot`).
2. CLI-—Å–∫—Ä–∏–ø—Ç—ã –¥–ª—è –∑–∞–ø—É—Å–∫–æ–≤ `scheduler` –∏ `worker`.
3. Backend –æ–∂–∏–¥–∞–µ—Ç `scheduler.json`, —Å–æ–∑–¥–∞–µ—Ç `Client` –∏ –ø–µ—Ä–µ–¥–∞–µ—Ç `dask_client` –≤ `TPOTEstimator`.
4. Healthchecks –∏ auto-restart workers.

### Phase 3 ‚Äî –¢–µ—Å—Ç—ã –∏ rollout (1 –Ω–µ–¥–µ–ª—è)
1. Unit: —Ç–µ—Å—Ç—ã –¥–ª—è search spaces, trainer, serialization.
2. Integration: `pytest` —Å `time_left=30`, `parallel_mode=local`.
3. Smoke: Jobs —Å —Ä–∞–∑–Ω—ã–º–∏ dataset, –ø—Ä–æ–≤–µ—Ä–∫–∞ `leaderboard`.
4. Performance: 3 dataset (–º–∞–ª—ã–π/—Å—Ä–µ–¥–Ω–∏–π/—à—É–º–Ω—ã–π).
5. Canary: –≤–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è 10% –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ `tpot_parallel_fallbacks_total`.

---

## ‚öôÔ∏è –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ —Ä–µ–∂–∏–º—ã

### Local multi-core
- `TPOT_PARALLEL_MODE=local`, `TPOT__N_JOBS=min(cpu_count-1, 8)`.
- `TPOTEstimator(n_jobs=config.n_jobs, memory_limit=config.memory_limit, generations=config.generations, population_size=config.population_size)`.
- `if __name__ == "__main__"` guard –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω.

### Distributed (Dask)
1. Scheduler:
   ```bash
   dask-scheduler --scheduler-file /var/run/tpot/scheduler.json --idle-timeout 300
   ```
2. Worker:
   ```bash
   DASK_DISTRIBUTED__WORKER__DAEMON=False \
   dask-worker --nthreads 1 --memory-limit 0 --scheduler-file /var/run/tpot/scheduler.json
   ```
3. Backend:
   ```python
   client = Client(scheduler_file=config.scheduler_file)
   tpot = TPOTEstimator(dask_client=client)
   ```
4. Watchdog: –µ—Å–ª–∏ `Client` –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ª–æ–≥–∏—Ä—É–µ–º `tpot_parallel_fallbacks_total` –∏ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ `n_jobs=1`.

---

## üßÆ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ò—Å—Ç–æ—á–Ω–∏–∫ | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ | –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é |
|----------|----------|------------|--------------|
|`TPOT__GENERATIONS`|env/payload|–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–∫–æ–ª–µ–Ω–∏–π|40|
|`TPOT__POPULATION_SIZE`|env/payload|–†–∞–∑–º–µ—Ä –ø–æ–ø—É–ª—è—Ü–∏–∏|64|
|`TPOT__TIME_LEFT`|env/payload|–ë—é–¥–∂–µ—Ç –ø–æ–∏—Å–∫–∞ (—Å–µ–∫)|600|
|`TPOT__PER_RUN_LIMIT`|env/payload|–í—Ä–µ–º—è –Ω–∞ –º–æ–¥–µ–ª—å|60|
|`TPOT__METRIC`|payload|–ú–µ—Ç—Ä–∏–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏|`accuracy`/`r2`|
|`TPOT__CV_FOLDS`|env|CV folds|5|
|`TPOT__CONFIG_DICT`|env|Search space dict/ConfigSpace|
|`TPOT_PARALLEL_MODE`|env|`local` / `distributed` / `off`|local|
|`TPOT__N_JOBS`|env|–ß–∏—Å–ª–æ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤|`cpu_count-1`|
|`TPOT__MEMORY_LIMIT_MB`|env|–õ–∏–º–∏—Ç –ø–∞–º—è—Ç–∏ –Ω–∞ worker|3072|
|`TPOT__DASK_SCHEDULER_FILE`|env|–ü—É—Ç—å –∫ scheduler.json|/var/run/tpot/scheduler.json|
|`ENABLE_AUTOML_FALLBACK`|env|–†–∞–∑—Ä–µ—à–∏—Ç—å fallback|true|

Payload:
```json
{
  "dataset_id": "...",
  "target_column": "Revenue",
  "task": "auto",
  "time_left": 900,
  "per_run_limit": 60,
  "metric": "f1",
  "parallel_mode": "distributed",
  "generations": 20,
  "population_size": 32
}
```

---

## ‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ QA

1. **Unit**: –º–æ–∫ TPOT (`fit`, `predict`, `export_pipeline`), –ø—Ä–æ–≤–µ—Ä–∫–∞ `search_space`.
2. **Integration**: `pytest tests/test_training_service.py -k tpot`, Jobs —Å `time_left=30`, check `leaderboard` + `model.joblib`.
3. **Regression**: `ENABLE_AUTOML=false` ‚Üí fallback path.
4. **Performance**: 3 –¥–∞—Ç–∞—Å–µ—Ç–∞ (–º–∞–ª—ã–π/—Å—Ä–µ–¥–Ω–∏–π/—à—É–º–Ω—ã–π), –∏–∑–º–µ—Ä–∏—Ç—å `training_duration_seconds`, `tp_population_size`.
5. **Canary**: –≤–∫–ª—é—á–µ–Ω–∏–µ TPOT –¥–ª—è 10% –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ `tpot_parallel_fallbacks_total`.

---

## üìà –ù–∞–±–ª—é–¥–∞–µ–º–æ—Å—Ç—å –∏ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è

- Prometheus: `training_duration_seconds{mode="tpot"}`, `training_best_score{metric="accuracy"}`, `tpot_parallel_fallbacks_total`, `tp_generation`, `tp_population_size`.
- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ: `TPOTEstimator.evaluated_individuals` (JSON snippet), `leaderboard_topk`, `Pareto_Front`.
- Alerting: >3 –æ—à–∏–±–æ–∫ TPOT –ø–æ–¥—Ä—è–¥, `training_duration_seconds > TPOT__TIME_LEFT`, `parallel fallback`.

---

## ‚ö†Ô∏è –†–∏—Å–∫–∏ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

| –†–∏—Å–∫ | –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å | –í–ª–∏—è–Ω–∏–µ | –ú–∏—Ç–∏–≥–∏—Ä—É—é—â–∏–µ –º–µ—Ä—ã |
|------|------------|---------|------------------|
|–°–ª–æ–∂–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ TPOT|–°—Ä–µ–¥–Ω—è—è|–í—ã—Å–æ–∫–æ–µ|CI –∫–µ—à–∏—Ä—É–µ—Ç wheels, –æ—Ç–¥–µ–ª—å–Ω—ã–π layer —Å build deps|
|OOM –ø—Ä–∏ –±–æ–ª—å—à–∏—Ö search spaces|–°—Ä–µ–¥–Ω—è—è|–°—Ä–µ–¥–Ω–µ–µ|–õ–∏–º–∏—Ç—ã `TPOT__MEMORY_LIMIT_MB`, –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ Dask|
|–ù–µ—É—Å—Ç–æ—è–≤—à–∏–π—Å—è Dask|–°—Ä–µ–¥–Ω—è—è|–°—Ä–µ–¥–Ω–µ–µ|Healthchecks, auto-restart, fallback –Ω–∞ local|
|–î–æ–ª–≥–æ–µ –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞ Jobs|–°—Ä–µ–¥–Ω—è—è|–°—Ä–µ–¥–Ω–µ–µ|`per_run_limit`, `time_left`, `parallel_mode` guard|
|–ù–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –±–µ–∑ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è|–ù–∏–∑–∫–∞—è|–ù–∏–∑–∫–æ–µ|UI –ø–æ–∫–∞ —Å–∫—Ä—ã–≤–∞–µ—Ç –ø–æ–ª—è, API —Å–æ–≤–º–µ—Å—Ç–∏–º|

---

## üöÄ –ü–ª–∞–Ω —Ä–∞—Å–∫–∞—Ç–∫–∏

1. **Week 1 (Dev)**: –≤–∫–ª—é—á–∏—Ç—å TPOT –≤ dev, –ª–æ–∫–∞–ª—å–Ω—ã–π `n_jobs`.
2. **Week 2 (Staging)**: –ø–æ–¥–Ω—è—Ç—å scheduler/workers, –ø—Ä–æ–≥–Ω–∞—Ç—å —Ç–µ—Å—Ç—ã, smoke –Ω–∞ 3 –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö.
3. **Week 3 (Prod Canary)**: 10% –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π —Ä–µ–∂–∏–º `distributed`.
4. **Week 4 (Prod GA)**: –≤–∫–ª—é—á–∏—Ç—å –¥–ª—è –≤—Å–µ—Ö, –º–µ—Ç—Ä–∏–∫–∏ –≤ UI.
5. **Post-GA**: performance tuning, –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ search spaces, –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è.

---

## üìù –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –æ–±—É—á–µ–Ω–∏–µ

- –û–±–Ω–æ–≤–∏—Ç—å README (—Ä–∞–∑–¥–µ–ª Training) —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º TPOT —Ä–µ–∂–∏–º–æ–≤.
- –î–æ–±–∞–≤–∏—Ç—å playbook –¥–ª—è DevOps –ø–æ –∑–∞–ø—É—Å–∫—É scheduler/worker –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥—É `TPOT_PARALLEL_MODE`.
- –°—Å—ã–ª–∞—Ç—å Data Science –Ω–∞ `docs/tpot.md` –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤—ã—Ö search spaces / symbolic regression —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤.
- –ü—Ä–æ–≤–µ—Å—Ç–∏ –≤–æ—Ä–∫—à–æ–ø (AutoML overview, `leaderboard`, `TPOTEstimator.evaluated_individuals`).
- –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å FAQ –ø–æ —Å–±–æ—Ä–∫–µ –æ–±—Ä–∞–∑–∞, c–±–æ—Ä–∫–µ –∫–æ–ª—ë—Å, –ª–∏–º–∏—Ç–∞–º –≤—Ä–µ–º–µ–Ω–∏.

---

**–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π**: ML Platform Team
**–î–æ–∫—É–º–µ–Ω—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω**: GitHub Copilot (Draft)
**–°–ª–µ–¥—É—é—â–∏–π –ø–µ—Ä–µ—Å–º–æ—Ç—Ä**: –ø–æ—Å–ª–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è —Å DevOps –∏ Data Science
